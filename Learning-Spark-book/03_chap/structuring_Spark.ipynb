{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 Underneath an RDD and The DataFrame API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating structures from list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"structuring_Spark\")\n",
    "    .getOrCreate()\n",
    "    )\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Brooke', 22.5), ('TD', 35.0), ('Denny', 31.0), ('Jules', 30.0)]\n"
     ]
    }
   ],
   "source": [
    "# creating RDD\n",
    "dataRDD = sc.parallelize(\n",
    "    [(\"Brooke\", 20), (\"Denny\", 31), (\"Jules\", 30), (\"TD\", 35), (\"Brooke\", 25)]\n",
    "    )\n",
    "# aggregating to get mean age\n",
    "agesRDD = (\n",
    "    dataRDD\n",
    "    .map(lambda x: (x[0], (x[1], 1)))\n",
    "    .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1])) \n",
    "    .map(lambda x: (x[0], x[1][0]/x[1][1]))\n",
    "    )\n",
    "print(agesRDD.take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now with DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|  name|avg(age)|\n",
      "+------+--------+\n",
      "|Brooke|    22.5|\n",
      "| Denny|    31.0|\n",
      "| Jules|    30.0|\n",
      "|    TD|    35.0|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating df from list\n",
    "data_df = spark.createDataFrame(\n",
    "    [(\"Brooke\", 20), (\"Denny\", 31), (\"Jules\", 30), (\"TD\", 35), (\"Brooke\", 25)],\n",
    "    [\"name\", \"age\"]\n",
    "    )\n",
    "# aggregating\n",
    "agg_df = data_df.groupBy(\"name\").agg(F.avg(\"age\"))\n",
    "agg_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The DataFrame API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "|  1|    Jules|  Damji|https://tinyurl.1| 1/4/2016| 4535| [twitter, LinkedIn]|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2| 5/5/2018| 8908| [twitter, LinkedIn]|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3| 6/7/2019| 7659|[web, twitter, FB...|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|5/12/2018|10568|       [twitter, FB]|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB...|\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6| 3/2/2015|25568| [twitter, LinkedIn]|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "\n",
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- First: string (nullable = true)\n",
      " |-- Last: string (nullable = true)\n",
      " |-- Url: string (nullable = true)\n",
      " |-- Published: string (nullable = true)\n",
      " |-- Hits: integer (nullable = true)\n",
      " |-- Campaigns: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "schema = \"`Id` INT, `First` STRING, `Last` STRING, `Url` STRING, \" + \\\n",
    "    \"`Published` STRING, `Hits` INT, `Campaigns` ARRAY<STRING>\"\n",
    "data = [\n",
    "    [1, \"Jules\", \"Damji\", \"https://tinyurl.1\", \"1/4/2016\", 4535, [\"twitter\", \"LinkedIn\"]],\n",
    "    [2, \"Brooke\",\"Wenig\", \"https://tinyurl.2\", \"5/5/2018\", 8908, [\"twitter\", \"LinkedIn\"]],\n",
    "    [3, \"Denny\", \"Lee\", \"https://tinyurl.3\", \"6/7/2019\", 7659, [\"web\", \"twitter\", \"FB\", \"LinkedIn\"]],\n",
    "    [4, \"Tathagata\", \"Das\", \"https://tinyurl.4\", \"5/12/2018\", 10568, [\"twitter\", \"FB\"]],\n",
    "    [5, \"Matei\",\"Zaharia\", \"https://tinyurl.5\", \"5/14/2014\", 40578, [\"web\", \"twitter\", \"FB\", \"LinkedIn\"]],\n",
    "    [6, \"Reynold\", \"Xin\", \"https://tinyurl.6\", \"3/2/2015\", 25568, [\"twitter\", \"LinkedIn\"]]\n",
    "    ]\n",
    "blogs_df = spark.createDataFrame(data, schema)\n",
    "blogs_df.show()\n",
    "print(blogs_df.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "|  1|    Jules|  Damji|https://tinyurl.1| 1/4/2016| 4535| [twitter, LinkedIn]|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2| 5/5/2018| 8908| [twitter, LinkedIn]|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3| 6/7/2019| 7659|[web, twitter, FB...|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|5/12/2018|10568|       [twitter, FB]|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB...|\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6| 3/2/2015|25568| [twitter, LinkedIn]|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "\n",
      "root\n",
      " |-- Id: integer (nullable = false)\n",
      " |-- First: string (nullable = false)\n",
      " |-- Last: string (nullable = false)\n",
      " |-- Url: string (nullable = false)\n",
      " |-- Published: string (nullable = false)\n",
      " |-- Hits: integer (nullable = false)\n",
      " |-- Campaigns: array (nullable = false)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Or with classes\n",
    "schema = StructType([\n",
    "   StructField(\"Id\", IntegerType(), False),\n",
    "   StructField(\"First\", StringType(), False),\n",
    "   StructField(\"Last\", StringType(), False),\n",
    "   StructField(\"Url\", StringType(), False),\n",
    "   StructField(\"Published\", StringType(), False),\n",
    "   StructField(\"Hits\", IntegerType(), False),\n",
    "   StructField(\"Campaigns\", ArrayType(StringType()), False)]\n",
    "   )\n",
    "blogs_df = spark.createDataFrame(data, schema)\n",
    "blogs_df.show()\n",
    "print(blogs_df.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Columns manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|(Hits * 2)|\n",
      "+----------+\n",
      "|      9070|\n",
      "|     17816|\n",
      "+----------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+----------+\n",
      "|(Hits * 2)|\n",
      "+----------+\n",
      "|      9070|\n",
      "|     17816|\n",
      "+----------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+----------+\n",
      "|(Hits * 2)|\n",
      "+----------+\n",
      "|      9070|\n",
      "|     17816|\n",
      "+----------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+-----------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|Big Hitters|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+-----------+\n",
      "|  1|    Jules|  Damji|https://tinyurl.1| 1/4/2016| 4535| [twitter, LinkedIn]|      false|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2| 5/5/2018| 8908| [twitter, LinkedIn]|      false|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3| 6/7/2019| 7659|[web, twitter, FB...|      false|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|5/12/2018|10568|       [twitter, FB]|       true|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB...|       true|\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6| 3/2/2015|25568| [twitter, LinkedIn]|       true|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+-----------+\n",
      "\n",
      "StructType([StructField('Id', IntegerType(), False), StructField('First', StringType(), False), StructField('Last', StringType(), False), StructField('Url', StringType(), False), StructField('Published', StringType(), False), StructField('Hits', IntegerType(), False), StructField('Campaigns', ArrayType(StringType(), True), False)])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "blogs_df.select(F.expr(\"Hits\") * 2).show(2)\n",
    "blogs_df.select(F.col(\"Hits\") * 2).show(2)\n",
    "blogs_df.select(F.expr(\"Hits * 2\")).show(2)\n",
    "# show heavy hitters\n",
    "blogs_df.withColumn(\"Big Hitters\", (F.expr(\"Hits > 10000\"))).show()\n",
    "print(blogs_df.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|    AuthorsId|\n",
      "+-------------+\n",
      "|  JulesDamji1|\n",
      "| BrookeWenig2|\n",
      "|    DennyLee3|\n",
      "|TathagataDas4|\n",
      "+-------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# concatenating columns\n",
    "(\n",
    "    blogs_df\n",
    "    .withColumn(\"AuthorsId\", (F.concat(F.expr(\"First\"), F.expr(\"Last\"), F.expr(\"Id\")))) \n",
    "    .select(F.col(\"AuthorsId\"))\n",
    "    .show(4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6| 3/2/2015|25568| [twitter, LinkedIn]|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB...|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|5/12/2018|10568|       [twitter, FB]|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3| 6/7/2019| 7659|[web, twitter, FB...|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2| 5/5/2018| 8908| [twitter, LinkedIn]|\n",
      "|  1|    Jules|  Damji|https://tinyurl.1| 1/4/2016| 4535| [twitter, LinkedIn]|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sorting\n",
    "blogs_df.sort(F.col(\"Id\").desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Row(6, 'Reynold', 'Xin', 'https://tinyurl.6', 255568, '3/2/2015', ['twitter', 'LinkedIn'])>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_row = Row(6, \"Reynold\", \"Xin\", \"https://tinyurl.6\", 255568, \"3/2/2015\",\n",
    "[\"twitter\", \"LinkedIn\"])\n",
    "blog_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|      Authors|State|\n",
      "+-------------+-----+\n",
      "|Matei Zaharia|   CA|\n",
      "|  Reynold Xin|   CA|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating dataframe from rows\n",
    "rows = [Row(\"Matei Zaharia\", \"CA\"), Row(\"Reynold Xin\", \"CA\")]\n",
    "authors_df = spark.createDataFrame(rows, [\"Authors\", \"State\"])\n",
    "authors_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Readers and Data Writers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_schema = StructType([\n",
    "    StructField('CallNumber', IntegerType(), True),\n",
    "    StructField('UnitID', StringType(), True),\n",
    "    StructField('IncidentNumber', IntegerType(), True),\n",
    "    StructField('CallType', StringType(), True),\n",
    "    StructField('CallDate', StringType(), True),\n",
    "    StructField('WatchDate', StringType(), True),\n",
    "    StructField('CallFinalDisposition', StringType(), True),\n",
    "    StructField('AvailableDtTm', StringType(), True),\n",
    "    StructField('Address', StringType(), True),\n",
    "    StructField('City', StringType(), True),\n",
    "    StructField('Zipcode', IntegerType(), True),\n",
    "    StructField('Battalion', StringType(), True),\n",
    "    StructField('StationArea', StringType(), True),\n",
    "    StructField('Box', StringType(), True),\n",
    "    StructField('OriginalPriority', StringType(), True),\n",
    "    StructField('Priority', StringType(), True),\n",
    "    StructField('FinalPriority', IntegerType(), True),\n",
    "    StructField('ALSUnit', BooleanType(), True),\n",
    "    StructField('CallTypeGroup', StringType(), True),\n",
    "    StructField('NumAlarms', IntegerType(), True),\n",
    "    StructField('UnitType', StringType(), True),\n",
    "    StructField('UnitSequenceInCallDispatch', IntegerType(), True),\n",
    "    StructField('FirePreventionDistrict', StringType(), True),\n",
    "    StructField('SupervisorDistrict', StringType(), True),\n",
    "    StructField('Neighborhood', StringType(), True),\n",
    "    StructField('Location', StringType(), True),\n",
    "    StructField('RowID', StringType(), True),\n",
    "    StructField('Delay', FloatType(), True)\n",
    "    ])\n",
    "sf_fire_file = \"./data/sf-fire-calls.csv\"\n",
    "fire_df = spark.read.csv(sf_fire_file, header=True, schema=fire_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|CallNumber|UnitID|IncidentNumber|        CallType|  CallDate| WatchDate|CallFinalDisposition|       AvailableDtTm|             Address|City|Zipcode|Battalion|StationArea| Box|OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|        Neighborhood|            Location|        RowID|    Delay|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|  20110016|   T13|       2003235|  Structure Fire|01/11/2002|01/10/2002|               Other|01/11/2002 01:51:...|2000 Block of CAL...|  SF|  94109|      B04|         38|3362|               3|       3|            3|  false|         NULL|        1|   TRUCK|                         2|                     4|                 5|     Pacific Heights|(37.7895840679362...|020110016-T13|     2.95|\n",
      "|  20110022|   M17|       2003241|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 03:01:...|0 Block of SILVER...|  SF|  94124|      B10|         42|6495|               3|       3|            3|   true|         NULL|        1|   MEDIC|                         1|                    10|                10|Bayview Hunters P...|(37.7337623673897...|020110022-M17|      4.7|\n",
      "|  20110023|   M41|       2003242|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 02:39:...|MARKET ST/MCALLIS...|  SF|  94102|      B03|         01|1455|               3|       3|            3|   true|         NULL|        1|   MEDIC|                         2|                     3|                 6|          Tenderloin|(37.7811772186856...|020110023-M41|2.4333334|\n",
      "|  20110032|   E11|       2003250|    Vehicle Fire|01/11/2002|01/10/2002|               Other|01/11/2002 04:16:...|APPLETON AV/MISSI...|  SF|  94110|      B06|         32|5626|               3|       3|            3|  false|         NULL|        1|  ENGINE|                         1|                     6|                 9|      Bernal Heights|(37.7388432849018...|020110032-E11|      1.5|\n",
      "|  20110043|   B04|       2003259|          Alarms|01/11/2002|01/10/2002|               Other|01/11/2002 06:01:...|1400 Block of SUT...|  SF|  94109|      B04|         03|3223|               3|       3|            3|  false|         NULL|        1|   CHIEF|                         2|                     4|                 2|    Western Addition|(37.7872890372638...|020110043-B04|3.4833333|\n",
      "|  20110072|   T08|       2003279|  Structure Fire|01/11/2002|01/11/2002|               Other|01/11/2002 08:03:...|  BEALE ST/FOLSOM ST|  SF|  94105|      B03|         35|2122|               3|       3|            3|  false|         NULL|        1|   TRUCK|                         2|                     3|                 6|Financial Distric...|(37.7886866619654...|020110072-T08|     1.75|\n",
      "|  20110125|   E33|       2003301|          Alarms|01/11/2002|01/11/2002|               Other|01/11/2002 09:46:...|0 Block of FARALL...|  SF|  94112|      B09|         33|8324|               3|       3|            3|  false|         NULL|        1|  ENGINE|                         2|                     9|                11|Oceanview/Merced/...|(37.7140353531157...|020110125-E33|2.7166667|\n",
      "|  20110130|   E36|       2003304|          Alarms|01/11/2002|01/11/2002|               Other|01/11/2002 09:58:...|600 Block of POLK ST|  SF|  94102|      B02|         03|3114|               3|       3|            3|  false|         NULL|        1|  ENGINE|                         1|                     2|                 6|          Tenderloin|(37.7826266328595...|020110130-E36|1.7833333|\n",
      "|  20110197|   E05|       2003343|Medical Incident|01/11/2002|01/11/2002|               Other|01/11/2002 12:06:...|1500 Block of WEB...|  SF|  94115|      B04|         05|3513|               3|       3|            3|  false|         NULL|        1|  ENGINE|                         1|                     4|                 5|           Japantown|(37.784958590666,...|020110197-E05|1.5166667|\n",
      "|  20110215|   E06|       2003348|Medical Incident|01/11/2002|01/11/2002|               Other|01/11/2002 01:08:...|DIAMOND ST/MARKET ST|  SF|  94114|      B05|         06|5415|               3|       3|            3|  false|         NULL|        1|  ENGINE|                         1|                     5|                 8| Castro/Upper Market|(37.7618954753708...|020110215-E06|2.7666667|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/05 22:29:20 WARN MemoryManager: Total allocation exceeds 95,00% (991 166 452 bytes) of heap memory\n",
      "Scaling row group sizes to 92,31% for 8 writers\n",
      "25/05/05 22:29:20 WARN MemoryManager: Total allocation exceeds 95,00% (991 166 452 bytes) of heap memory\n",
      "Scaling row group sizes to 82,05% for 9 writers\n",
      "25/05/05 22:29:20 WARN MemoryManager: Total allocation exceeds 95,00% (991 166 452 bytes) of heap memory\n",
      "Scaling row group sizes to 73,85% for 10 writers\n",
      "25/05/05 22:29:20 WARN MemoryManager: Total allocation exceeds 95,00% (991 166 452 bytes) of heap memory\n",
      "Scaling row group sizes to 67,13% for 11 writers\n",
      "25/05/05 22:29:21 WARN MemoryManager: Total allocation exceeds 95,00% (991 166 452 bytes) of heap memory\n",
      "Scaling row group sizes to 73,85% for 10 writers\n",
      "25/05/05 22:29:21 WARN MemoryManager: Total allocation exceeds 95,00% (991 166 452 bytes) of heap memory\n",
      "Scaling row group sizes to 82,05% for 9 writers\n",
      "25/05/05 22:29:21 WARN MemoryManager: Total allocation exceeds 95,00% (991 166 452 bytes) of heap memory\n",
      "Scaling row group sizes to 92,31% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# saving as parquet\n",
    "parquet_path = \"./data/saved_parquet\"\n",
    "fire_df.write.format(\"parquet\").save(parquet_path, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/05 22:29:22 WARN MemoryManager: Total allocation exceeds 95,00% (991 166 452 bytes) of heap memory\n",
      "Scaling row group sizes to 92,31% for 8 writers\n",
      "25/05/05 22:29:22 WARN MemoryManager: Total allocation exceeds 95,00% (991 166 452 bytes) of heap memory\n",
      "Scaling row group sizes to 82,05% for 9 writers\n",
      "25/05/05 22:29:22 WARN MemoryManager: Total allocation exceeds 95,00% (991 166 452 bytes) of heap memory\n",
      "Scaling row group sizes to 73,85% for 10 writers\n",
      "25/05/05 22:29:22 WARN MemoryManager: Total allocation exceeds 95,00% (991 166 452 bytes) of heap memory\n",
      "Scaling row group sizes to 67,13% for 11 writers\n",
      "25/05/05 22:29:22 WARN MemoryManager: Total allocation exceeds 95,00% (991 166 452 bytes) of heap memory\n",
      "Scaling row group sizes to 73,85% for 10 writers\n",
      "25/05/05 22:29:22 WARN MemoryManager: Total allocation exceeds 95,00% (991 166 452 bytes) of heap memory\n",
      "Scaling row group sizes to 82,05% for 9 writers\n",
      "25/05/05 22:29:22 WARN MemoryManager: Total allocation exceeds 95,00% (991 166 452 bytes) of heap memory\n",
      "Scaling row group sizes to 92,31% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# saving as table\n",
    "parquet_table = \"test_table\"\n",
    "_ = spark.sql(f\"DROP TABLE IF EXISTS {parquet_table}\")\n",
    "fire_df.write.format(\"parquet\").saveAsTable(parquet_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|CallNumber|UnitID|IncidentNumber|        CallType|  CallDate| WatchDate|CallFinalDisposition|       AvailableDtTm|             Address|City|Zipcode|Battalion|StationArea| Box|OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|      UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|        Neighborhood|            Location|        RowID|    Delay|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|   1850050|   M15|         55301|Medical Incident|07/03/2000|07/02/2000|               Other|07/03/2000 07:38:...|200 Block of SAN ...|  SF|  94127|      B09|         39|8554|               3|       3|            3|   true|         NULL|        1|         MEDIC|                         2|                     9|                 7|  West of Twin Peaks|(37.7325253339799...|001850050-M15|5.0833335|\n",
      "|   1850058|   T01|         55309|          Alarms|07/03/2000|07/02/2000|               Other|07/03/2000 07:05:...| 100 Block of 9TH ST|  SF|  94103|      B02|         36|2336|               3|       3|            3|   true|         NULL|        1|         TRUCK|                         3|                     2|                 6|     South of Market|(37.7751756623626...|001850058-T01|2.7666667|\n",
      "|   1850065|   RC2|         55316|Medical Incident|07/03/2000|07/02/2000|               Other|07/03/2000 08:03:...|2000 Block of MIS...|  SF|  94110|      B02|         07|5236|               3|       3|            3|   true|         NULL|        1|RESCUE CAPTAIN|                         3|                     2|                 9|             Mission|(37.7642444942899...|001850065-RC2|      2.7|\n",
      "|   1850070|   M03|         55321|Medical Incident|07/03/2000|07/03/2000|               Other|07/03/2000 09:01:...|    6TH ST/MARKET ST|  SF|  94102|      B03|         01|2248|               3|       3|            3|   true|         NULL|        1|         MEDIC|                         2|                     3|                 6|     South of Market|(37.7822305756448...|001850070-M03|2.8666666|\n",
      "|   1850104|   E08|         55354|Medical Incident|07/03/2000|07/03/2000|               Other|07/03/2000 11:26:...|   4TH ST/BRANNAN ST|  SF|  94107|      B03|         08|2223|               3|       3|            3|  false|         NULL|        1|        ENGINE|                         2|                     3|                 6|     South of Market|(37.7783268314649...|001850104-E08|1.5166667|\n",
      "|   1850113|   E17|         55363|  Structure Fire|07/03/2000|07/03/2000|               Other|07/03/2000 11:59:...|  3RD ST/BANCROFT AV|  SF|  94124|      B10|         17|6537|               3|       3|            3|  false|         NULL|        1|        ENGINE|                         1|                    10|                10|Bayview Hunters P...|(37.7262373966555...|001850113-E17|7.2166667|\n",
      "|   1850115|   M36|         55365|Medical Incident|07/03/2000|07/03/2000|               Other|07/03/2000 01:11:...|500 Block of VALE...|  SF|  94110|      B02|         07|5247|               2|       2|            2|   true|         NULL|        1|         MEDIC|                         1|                     2|                 8|             Mission|(37.7641044099588...|001850115-M36| 8.666667|\n",
      "|   1850122|   B07|         55372|  Structure Fire|07/03/2000|07/03/2000|               Other|07/03/2000 02:25:...|1500 Block of GRO...|  SF|  94117|      B05|         21|4253|               3|       3|            3|  false|         NULL|        3|         CHIEF|                        24|                     5|                 5|   Lone Mountain/USF|(37.7754543454069...|001850122-B07|5.7166667|\n",
      "|   1850124|    D1|         55373|  Structure Fire|07/03/2000|07/03/2000|               Other|07/03/2000 12:33:...|     BAY ST/MASON ST|  SF|  94133|      B01|         28|1425|               3|       3|            3|  false|         NULL|        1|         CHIEF|                         5|                     1|                 3|         North Beach|(37.8056184799358...| 001850124-D1| 4.983333|\n",
      "|   1850132|   M09|         55382|Medical Incident|07/03/2000|07/03/2000|               Other|07/03/2000 01:32:...|200 Block of BAY ...|  SF|  94124|      B10|         09|6375|               3|       3|            3|   true|         NULL|        1|         MEDIC|                         2|                    10|                10|Bayview Hunters P...|(37.7442404121423...|001850132-M09|1.9166666|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.table(parquet_table).show(10)\n",
    "_ = spark.sql(f\"DROP TABLE IF EXISTS {parquet_table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------+--------------+\n",
      "|IncidentNumber|AvailableDtTm         |CallType      |\n",
      "+--------------+----------------------+--------------+\n",
      "|2003235       |01/11/2002 01:51:44 AM|Structure Fire|\n",
      "|2003250       |01/11/2002 04:16:46 AM|Vehicle Fire  |\n",
      "|2003259       |01/11/2002 06:01:58 AM|Alarms        |\n",
      "|2003279       |01/11/2002 08:03:26 AM|Structure Fire|\n",
      "|2003301       |01/11/2002 09:46:44 AM|Alarms        |\n",
      "+--------------+----------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# where\n",
    "few_fire_df = (fire_df\n",
    "    .select(\"IncidentNumber\", \"AvailableDtTm\", \"CallType\")\n",
    "    .where(F.col(\"CallType\") != \"Medical Incident\"))\n",
    "few_fire_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------+--------------+\n",
      "|IncidentNumber|AvailableDtTm         |CallType      |\n",
      "+--------------+----------------------+--------------+\n",
      "|2003235       |01/11/2002 01:51:44 AM|Structure Fire|\n",
      "|2003250       |01/11/2002 04:16:46 AM|Vehicle Fire  |\n",
      "|2003259       |01/11/2002 06:01:58 AM|Alarms        |\n",
      "|2003279       |01/11/2002 08:03:26 AM|Structure Fire|\n",
      "|2003301       |01/11/2002 09:46:44 AM|Alarms        |\n",
      "+--------------+----------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter\n",
    "few_fire_df = (fire_df\n",
    "    .select(\"IncidentNumber\", \"AvailableDtTm\", \"CallType\")\n",
    "    .filter(F.col(\"CallType\") != \"Medical Incident\"))\n",
    "few_fire_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 103:>                                                      (0 + 11) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DistinctCallTypes|\n",
      "+-----------------+\n",
      "|               30|\n",
      "+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# count distinct\n",
    "(\n",
    "    fire_df\n",
    "    .select(\"CallType\")\n",
    "    .where(F.col(\"CallType\").isNotNull())\n",
    "    .agg(F.countDistinct(\"CallType\").alias(\"DistinctCallTypes\"))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|CallType                     |\n",
      "+-----------------------------+\n",
      "|Elevator / Escalator Rescue  |\n",
      "|Aircraft Emergency           |\n",
      "|Alarms                       |\n",
      "|Odor (Strange / Unknown)     |\n",
      "|Citizen Assist / Service Call|\n",
      "|HazMat                       |\n",
      "|Explosion                    |\n",
      "|Oil Spill                    |\n",
      "|Vehicle Fire                 |\n",
      "|Suspicious Package           |\n",
      "+-----------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# output distinct ones themselves\n",
    "(\n",
    "    fire_df\n",
    "    .select(\"CallType\")\n",
    "    .where(F.col(\"CallType\").isNotNull())\n",
    "    .distinct()\n",
    "    .show(10, False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|ResponseDelayedinMins|\n",
      "+---------------------+\n",
      "|5.35                 |\n",
      "|6.25                 |\n",
      "|5.2                  |\n",
      "|5.6                  |\n",
      "|7.25                 |\n",
      "+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# renaming F.columns\n",
    "new_fire_df = fire_df.withColumnRenamed(\"Delay\", \"ResponseDelayedinMins\")\n",
    "(\n",
    "    new_fire_df\n",
    "    .select(\"ResponseDelayedinMins\")\n",
    "    .where(F.col(\"ResponseDelayedinMins\") > 5)\n",
    "    .show(5, False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+\n",
      "|IncidentDate       |OnWatchDate        |AvailableDtTS      |\n",
      "+-------------------+-------------------+-------------------+\n",
      "|2002-11-01 00:00:00|2002-10-01 00:00:00|2002-11-01 01:51:44|\n",
      "|2002-11-01 00:00:00|2002-10-01 00:00:00|2002-11-01 03:01:18|\n",
      "|2002-11-01 00:00:00|2002-10-01 00:00:00|2002-11-01 02:39:50|\n",
      "|2002-11-01 00:00:00|2002-10-01 00:00:00|2002-11-01 04:16:46|\n",
      "|2002-11-01 00:00:00|2002-10-01 00:00:00|2002-11-01 06:01:58|\n",
      "+-------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# formating\n",
    "fire_ts_df = (\n",
    "    new_fire_df\n",
    "    .withColumn(\"IncidentDate\", F.to_timestamp(F.col(\"CallDate\"), \"dd/MM/yyyy\"))\n",
    "    .drop(\"CallDate\")\n",
    "    .withColumn(\"OnWatchDate\", F.to_timestamp(F.col(\"WatchDate\"), \"dd/MM/yyyy\"))\n",
    "    .drop(\"WatchDate\")\n",
    "    .withColumn(\"AvailableDtTS\", F.to_timestamp(F.col(\"AvailableDtTm\"), \"dd/MM/yyyy hh:mm:ss a\"))\n",
    "    .drop(\"AvailableDtTm\")\n",
    "    )\n",
    "# Select the converted F.columns\n",
    "(\n",
    "    fire_ts_df\n",
    "    .select(\"IncidentDate\", \"OnWatchDate\", \"AvailableDtTS\")\n",
    "    .show(5, False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 114:>                                                      (0 + 11) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|year(IncidentDate)|\n",
      "+------------------+\n",
      "|              NULL|\n",
      "|              2000|\n",
      "|              2001|\n",
      "|              2002|\n",
      "|              2003|\n",
      "|              2004|\n",
      "|              2005|\n",
      "|              2006|\n",
      "|              2007|\n",
      "|              2008|\n",
      "|              2009|\n",
      "|              2010|\n",
      "|              2011|\n",
      "|              2012|\n",
      "|              2013|\n",
      "|              2014|\n",
      "|              2015|\n",
      "|              2016|\n",
      "|              2017|\n",
      "|              2018|\n",
      "+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# date_trunc (kinda)\n",
    "(\n",
    "    fire_ts_df\n",
    "    .select(F.year('IncidentDate'))\n",
    "    .distinct()\n",
    "    .orderBy(F.year('IncidentDate'))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+------+\n",
      "|CallType                       |count |\n",
      "+-------------------------------+------+\n",
      "|Medical Incident               |113794|\n",
      "|Structure Fire                 |23319 |\n",
      "|Alarms                         |19406 |\n",
      "|Traffic Collision              |7013  |\n",
      "|Citizen Assist / Service Call  |2524  |\n",
      "|Other                          |2166  |\n",
      "|Outside Fire                   |2094  |\n",
      "|Vehicle Fire                   |854   |\n",
      "|Gas Leak (Natural and LP Gases)|764   |\n",
      "|Water Rescue                   |755   |\n",
      "+-------------------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# groupBy\n",
    "(   \n",
    "    fire_ts_df\n",
    "    .select(\"CallType\")\n",
    "    .where(F.col(\"CallType\").isNotNull())\n",
    "    .groupBy(\"CallType\")\n",
    "    .count()\n",
    "    .orderBy(\"count\", ascending=False)\n",
    "    .show(n=10, truncate=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------------+--------------------------+--------------------------+\n",
      "|sum(NumAlarms)|avg(ResponseDelayedinMins)|min(ResponseDelayedinMins)|max(ResponseDelayedinMins)|\n",
      "+--------------+--------------------------+--------------------------+--------------------------+\n",
      "|        176170|         3.892364154521585|               0.016666668|                   1844.55|\n",
      "+--------------+--------------------------+--------------------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AKA describe()\n",
    "(\n",
    "    fire_ts_df.select(\n",
    "        F.sum(\"NumAlarms\"),\n",
    "        F.avg(\"ResponseDelayedinMins\"),\n",
    "        F.min(\"ResponseDelayedinMins\"),\n",
    "        F.max(\"ResponseDelayedinMins\"),\n",
    "    ).show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
