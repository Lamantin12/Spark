{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"07_chap\")\n",
    "    .config(\"spark.sql.catalogImplementation\", \"hive\")\n",
    "    .getOrCreate()\n",
    "    )\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort-Merge Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/17 18:36:52 WARN TaskSetManager: Stage 0 contains a task of very large size (2105 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/05/17 18:36:56 WARN TaskSetManager: Stage 1 contains a task of very large size (3993 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+--------+--------+-----+-----+---+------+---------------------+----------+\n",
      "|transaction_id|quantity|users_id|amount  |state|items|uid|login |email                |user_state|\n",
      "+--------------+--------+--------+--------+-----+-----+---+------+---------------------+----------+\n",
      "|6183          |6183    |0       |12366.0 |TX   |SKU-0|0  |user_0|user_0@databricks.com|MI        |\n",
      "|19031         |19031   |0       |38062.0 |CA   |SKU-3|0  |user_0|user_0@databricks.com|MI        |\n",
      "|22870         |22870   |0       |45740.0 |NY   |SKU-1|0  |user_0|user_0@databricks.com|MI        |\n",
      "|26533         |26533   |0       |53066.0 |MI   |SKU-1|0  |user_0|user_0@databricks.com|MI        |\n",
      "|44187         |44187   |0       |88374.0 |MI   |SKU-5|0  |user_0|user_0@databricks.com|MI        |\n",
      "|59757         |59757   |0       |119514.0|NY   |SKU-2|0  |user_0|user_0@databricks.com|MI        |\n",
      "|67663         |67663   |0       |135326.0|CA   |SKU-3|0  |user_0|user_0@databricks.com|MI        |\n",
      "|68913         |68913   |0       |137826.0|NY   |SKU-3|0  |user_0|user_0@databricks.com|MI        |\n",
      "|80736         |80736   |0       |161472.0|MI   |SKU-5|0  |user_0|user_0@databricks.com|MI        |\n",
      "|83840         |83840   |0       |167680.0|AZ   |SKU-3|0  |user_0|user_0@databricks.com|MI        |\n",
      "|91255         |91255   |0       |182510.0|MI   |SKU-4|0  |user_0|user_0@databricks.com|MI        |\n",
      "|101170        |101170  |0       |202340.0|TX   |SKU-4|0  |user_0|user_0@databricks.com|MI        |\n",
      "|105553        |105553  |0       |211106.0|CA   |SKU-0|0  |user_0|user_0@databricks.com|MI        |\n",
      "|107493        |107493  |0       |214986.0|MI   |SKU-5|0  |user_0|user_0@databricks.com|MI        |\n",
      "|132569        |132569  |0       |265138.0|CA   |SKU-0|0  |user_0|user_0@databricks.com|MI        |\n",
      "|141596        |141596  |0       |283192.0|CA   |SKU-3|0  |user_0|user_0@databricks.com|MI        |\n",
      "|156094        |156094  |0       |312188.0|NY   |SKU-2|0  |user_0|user_0@databricks.com|MI        |\n",
      "|165481        |165481  |0       |330962.0|NY   |SKU-1|0  |user_0|user_0@databricks.com|MI        |\n",
      "|176660        |176660  |0       |353320.0|AZ   |SKU-5|0  |user_0|user_0@databricks.com|MI        |\n",
      "|183209        |183209  |0       |366418.0|TX   |SKU-4|0  |user_0|user_0@databricks.com|MI        |\n",
      "+--------------+--------+--------+--------+-----+-----+---+------+---------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")\n",
    "\n",
    "# Prepare mappings and RNG\n",
    "states = {\n",
    "    0: \"AZ\", 1: \"CO\", 2: \"CA\",\n",
    "    3: \"TX\", 4: \"NY\", 5: \"MI\"\n",
    "}\n",
    "items = {\n",
    "    0: \"SKU-0\", 1: \"SKU-1\", 2: \"SKU-2\",\n",
    "    3: \"SKU-3\", 4: \"SKU-4\", 5: \"SKU-5\"\n",
    "}\n",
    "rnd = random.Random(42)\n",
    "\n",
    "# Generate users data (uid, login, email, user_state)\n",
    "users_data = [\n",
    "    (\n",
    "        uid,\n",
    "        f\"user_{uid}\",\n",
    "        f\"user_{uid}@databricks.com\",\n",
    "        states[rnd.randint(0, 5)]\n",
    "    )\n",
    "    for uid in range(0, 1_000_001)\n",
    "]\n",
    "\n",
    "# Generate orders data\n",
    "# (transaction_id, quantity, users_id, amount, state, items)\n",
    "orders_data = [\n",
    "    (\n",
    "        tid,\n",
    "        tid,                             # quantity = tid (to match the Scala example)\n",
    "        rnd.randint(0, 9999),            # users_id\n",
    "        10 * tid * 0.2,                  # amount\n",
    "        states[rnd.randint(0, 5)],       # state\n",
    "        items[rnd.randint(0, 5)]         # item\n",
    "    )\n",
    "    for tid in range(0, 1_000_001)\n",
    "]\n",
    "\n",
    "# Create DataFrames\n",
    "usersDF = spark.createDataFrame(\n",
    "    users_data,\n",
    "    schema=[\"uid\", \"login\", \"email\", \"user_state\"]\n",
    ")\n",
    "\n",
    "ordersDF = spark.createDataFrame(\n",
    "    orders_data,\n",
    "    schema=[\"transaction_id\", \"quantity\", \"users_id\", \"amount\", \"state\", \"items\"]\n",
    ")\n",
    "\n",
    "# Perform the join\n",
    "usersOrdersDF = ordersDF.join(\n",
    "    usersDF,\n",
    "    ordersDF.users_id == usersDF.uid\n",
    ")\n",
    "\n",
    "# Show results\n",
    "usersOrdersDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- SortMergeJoin [users_id#10L], [uid#0L], Inner\n",
      "   :- Sort [users_id#10L ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(users_id#10L, 200), ENSURE_REQUIREMENTS, [plan_id=136]\n",
      "   :     +- Filter isnotnull(users_id#10L)\n",
      "   :        +- Scan ExistingRDD[transaction_id#8L,quantity#9L,users_id#10L,amount#11,state#12,items#13]\n",
      "   +- Sort [uid#0L ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(uid#0L, 200), ENSURE_REQUIREMENTS, [plan_id=137]\n",
      "         +- Filter isnotnull(uid#0L)\n",
      "            +- Scan ExistingRDD[uid#0L,login#1,email#2,user_state#3]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "usersOrdersDF.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/17 18:43:12 WARN TaskSetManager: Stage 16 contains a task of very large size (2105 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 17:>                                                       (0 + 12) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+--------+--------+-----+-----+---+------+---------------------+----------+\n",
      "|transaction_id|quantity|users_id|amount  |state|items|uid|login |email                |user_state|\n",
      "+--------------+--------+--------+--------+-----+-----+---+------+---------------------+----------+\n",
      "|4256          |4256    |0       |8512.0  |CO   |SKU-4|0  |user_0|user_0@databricks.com|MI        |\n",
      "|5772          |5772    |0       |11544.0 |CA   |SKU-3|0  |user_0|user_0@databricks.com|MI        |\n",
      "|11253         |11253   |0       |22506.0 |MI   |SKU-2|0  |user_0|user_0@databricks.com|MI        |\n",
      "|11359         |11359   |0       |22718.0 |CA   |SKU-5|0  |user_0|user_0@databricks.com|MI        |\n",
      "|48657         |48657   |0       |97314.0 |CA   |SKU-2|0  |user_0|user_0@databricks.com|MI        |\n",
      "|51286         |51286   |0       |102572.0|AZ   |SKU-1|0  |user_0|user_0@databricks.com|MI        |\n",
      "|69723         |69723   |0       |139446.0|CO   |SKU-4|0  |user_0|user_0@databricks.com|MI        |\n",
      "|88683         |88683   |0       |177366.0|TX   |SKU-3|0  |user_0|user_0@databricks.com|MI        |\n",
      "|89506         |89506   |0       |179012.0|MI   |SKU-3|0  |user_0|user_0@databricks.com|MI        |\n",
      "|98013         |98013   |0       |196026.0|CA   |SKU-5|0  |user_0|user_0@databricks.com|MI        |\n",
      "|99427         |99427   |0       |198854.0|CO   |SKU-3|0  |user_0|user_0@databricks.com|MI        |\n",
      "|100112        |100112  |0       |200224.0|NY   |SKU-1|0  |user_0|user_0@databricks.com|MI        |\n",
      "|112296        |112296  |0       |224592.0|TX   |SKU-0|0  |user_0|user_0@databricks.com|MI        |\n",
      "|115849        |115849  |0       |231698.0|CA   |SKU-5|0  |user_0|user_0@databricks.com|MI        |\n",
      "|128089        |128089  |0       |256178.0|AZ   |SKU-1|0  |user_0|user_0@databricks.com|MI        |\n",
      "|129694        |129694  |0       |259388.0|CO   |SKU-3|0  |user_0|user_0@databricks.com|MI        |\n",
      "|137207        |137207  |0       |274414.0|CA   |SKU-5|0  |user_0|user_0@databricks.com|MI        |\n",
      "|137340        |137340  |0       |274680.0|TX   |SKU-1|0  |user_0|user_0@databricks.com|MI        |\n",
      "|139598        |139598  |0       |279196.0|NY   |SKU-4|0  |user_0|user_0@databricks.com|MI        |\n",
      "|141046        |141046  |0       |282092.0|CA   |SKU-0|0  |user_0|user_0@databricks.com|MI        |\n",
      "+--------------+--------+--------+--------+-----+-----+---+------+---------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")\n",
    "\n",
    "# Prepare mappings and RNG\n",
    "states = {\n",
    "    0: \"AZ\", 1: \"CO\", 2: \"CA\",\n",
    "    3: \"TX\", 4: \"NY\", 5: \"MI\"\n",
    "}\n",
    "items = {\n",
    "    0: \"SKU-0\", 1: \"SKU-1\", 2: \"SKU-2\",\n",
    "    3: \"SKU-3\", 4: \"SKU-4\", 5: \"SKU-5\"\n",
    "}\n",
    "rnd = random.Random(42)\n",
    "\n",
    "# Generate users data (uid, login, email, user_state)\n",
    "users_data = [\n",
    "    (\n",
    "        uid,\n",
    "        f\"user_{uid}\",\n",
    "        f\"user_{uid}@databricks.com\",\n",
    "        states[rnd.randint(0, 5)]\n",
    "    )\n",
    "    for uid in range(0, 1_000)\n",
    "]\n",
    "\n",
    "# Generate orders data\n",
    "# (transaction_id, quantity, users_id, amount, state, items)\n",
    "orders_data = [\n",
    "    (\n",
    "        tid,\n",
    "        tid,                             # quantity = tid (to match the Scala example)\n",
    "        rnd.randint(0, 9999),            # users_id\n",
    "        10 * tid * 0.2,                  # amount\n",
    "        states[rnd.randint(0, 5)],       # state\n",
    "        items[rnd.randint(0, 5)]         # item\n",
    "    )\n",
    "    for tid in range(0, 1_000_001)\n",
    "]\n",
    "\n",
    "# Create DataFrames\n",
    "usersDF = spark.createDataFrame(\n",
    "    users_data,\n",
    "    schema=[\"uid\", \"login\", \"email\", \"user_state\"]\n",
    ")\n",
    "\n",
    "ordersDF = spark.createDataFrame(\n",
    "    orders_data,\n",
    "    schema=[\"transaction_id\", \"quantity\", \"users_id\", \"amount\", \"state\", \"items\"]\n",
    ")\n",
    "\n",
    "# Perform the join\n",
    "usersOrdersDF = ordersDF.join(\n",
    "    usersDF,\n",
    "    ordersDF.users_id == usersDF.uid\n",
    ")\n",
    "\n",
    "# Show results\n",
    "usersOrdersDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinedDF = ordersDF.join(broadcast(usersDF), ordersDF.users_id == usersDF.uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/17 18:44:29 WARN TaskSetManager: Stage 22 contains a task of very large size (2105 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 22:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+--------+------+-----+-----+---+--------+-----------------------+----------+\n",
      "|transaction_id|quantity|users_id|amount|state|items|uid|login   |email                  |user_state|\n",
      "+--------------+--------+--------+------+-----+-----+---+--------+-----------------------+----------+\n",
      "|5             |5       |986     |10.0  |NY   |SKU-5|986|user_986|user_986@databricks.com|TX        |\n",
      "|29            |29      |423     |58.0  |AZ   |SKU-1|423|user_423|user_423@databricks.com|NY        |\n",
      "|45            |45      |888     |90.0  |CO   |SKU-4|888|user_888|user_888@databricks.com|MI        |\n",
      "|53            |53      |224     |106.0 |NY   |SKU-3|224|user_224|user_224@databricks.com|MI        |\n",
      "|79            |79      |251     |158.0 |MI   |SKU-1|251|user_251|user_251@databricks.com|AZ        |\n",
      "|101           |101     |153     |202.0 |TX   |SKU-2|153|user_153|user_153@databricks.com|NY        |\n",
      "|110           |110     |359     |220.0 |MI   |SKU-3|359|user_359|user_359@databricks.com|AZ        |\n",
      "|112           |112     |803     |224.0 |NY   |SKU-5|803|user_803|user_803@databricks.com|NY        |\n",
      "|117           |117     |645     |234.0 |CA   |SKU-3|645|user_645|user_645@databricks.com|AZ        |\n",
      "|118           |118     |546     |236.0 |NY   |SKU-2|546|user_546|user_546@databricks.com|CA        |\n",
      "|138           |138     |742     |276.0 |AZ   |SKU-2|742|user_742|user_742@databricks.com|MI        |\n",
      "|150           |150     |992     |300.0 |TX   |SKU-2|992|user_992|user_992@databricks.com|AZ        |\n",
      "|164           |164     |258     |328.0 |CO   |SKU-2|258|user_258|user_258@databricks.com|TX        |\n",
      "|165           |165     |858     |330.0 |CO   |SKU-5|858|user_858|user_858@databricks.com|NY        |\n",
      "|172           |172     |510     |344.0 |AZ   |SKU-3|510|user_510|user_510@databricks.com|CO        |\n",
      "|194           |194     |982     |388.0 |NY   |SKU-4|982|user_982|user_982@databricks.com|CA        |\n",
      "|211           |211     |502     |422.0 |AZ   |SKU-5|502|user_502|user_502@databricks.com|AZ        |\n",
      "|227           |227     |125     |454.0 |CO   |SKU-2|125|user_125|user_125@databricks.com|CO        |\n",
      "|230           |230     |126     |460.0 |TX   |SKU-5|126|user_126|user_126@databricks.com|CO        |\n",
      "|235           |235     |693     |470.0 |TX   |SKU-0|693|user_693|user_693@databricks.com|NY        |\n",
      "+--------------+--------+--------+------+-----+-----+---+--------+-----------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/17 18:44:33 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 22 (TID 103): Attempting to kill Python Worker\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "joinedDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/17 18:50:05 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "25/05/17 18:50:05 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "25/05/17 18:50:09 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "25/05/17 18:50:09 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore khodosevichleo@198.18.1.200\n",
      "25/05/17 18:50:09 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException\n",
      "25/05/17 18:50:13 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
      "25/05/17 18:50:13 WARN HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist\n",
      "25/05/17 18:50:13 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "25/05/17 18:50:13 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "25/05/17 18:50:14 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n",
      "25/05/17 18:50:14 WARN TaskSetManager: Stage 27 contains a task of very large size (2105 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/05/17 18:50:15 WARN TaskSetManager: Stage 28 contains a task of very large size (2105 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/05/17 18:50:17 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 97,86% for 7 writers\n",
      "25/05/17 18:50:17 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 85,63% for 8 writers\n",
      "25/05/17 18:50:17 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 76,12% for 9 writers\n",
      "25/05/17 18:50:17 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 68,50% for 10 writers\n",
      "25/05/17 18:50:17 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 62,28% for 11 writers\n",
      "25/05/17 18:50:17 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 57,09% for 12 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 62,28% for 11 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 68,50% for 10 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 76,12% for 9 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 85,63% for 8 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 97,86% for 7 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 97,86% for 7 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 85,63% for 8 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 76,12% for 9 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 68,50% for 10 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 62,28% for 11 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 57,09% for 12 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 62,28% for 11 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 68,50% for 10 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 76,12% for 9 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 85,63% for 8 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 97,86% for 7 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 97,86% for 7 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 85,63% for 8 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 76,12% for 9 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 68,50% for 10 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 62,28% for 11 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 57,09% for 12 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 62,28% for 11 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 68,50% for 10 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 76,12% for 9 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 85,63% for 8 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 97,86% for 7 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 97,86% for 7 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 85,63% for 8 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 76,12% for 9 writers\n",
      "25/05/17 18:50:18 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 68,50% for 10 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 62,28% for 11 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 57,09% for 12 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 62,28% for 11 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 68,50% for 10 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 76,12% for 9 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 85,63% for 8 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 97,86% for 7 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 97,86% for 7 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 85,63% for 8 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 76,12% for 9 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 68,50% for 10 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 62,28% for 11 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 68,50% for 10 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 62,28% for 11 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 68,50% for 10 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 76,12% for 9 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 85,63% for 8 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 97,86% for 7 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 97,86% for 7 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 85,63% for 8 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 76,12% for 9 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 68,50% for 10 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 62,28% for 11 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 57,09% for 12 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 62,28% for 11 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 68,50% for 10 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 76,12% for 9 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 85,63% for 8 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 97,86% for 7 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 97,86% for 7 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 85,63% for 8 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 76,12% for 9 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 68,50% for 10 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 62,28% for 11 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 57,09% for 12 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 62,28% for 11 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 68,50% for 10 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 76,12% for 9 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 85,63% for 8 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 97,86% for 7 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 97,86% for 7 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 85,63% for 8 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 76,12% for 9 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 68,50% for 10 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 62,28% for 11 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 57,09% for 12 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 62,28% for 11 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 68,50% for 10 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 76,12% for 9 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 85,63% for 8 writers\n",
      "25/05/17 18:50:19 WARN MemoryManager: Total allocation exceeds 95,00% (919 443 854 bytes) of heap memory\n",
      "Scaling row group sizes to 97,86% for 7 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+--------+--------+-----+-----+---+------+---------------------+----------+\n",
      "|transaction_id|quantity|users_id|amount  |state|items|uid|login |email                |user_state|\n",
      "+--------------+--------+--------+--------+-----+-----+---+------+---------------------+----------+\n",
      "|20137         |20137   |2       |40274.0 |CO   |SKU-1|2  |user_2|user_2@databricks.com|AZ        |\n",
      "|36842         |36842   |2       |73684.0 |CO   |SKU-5|2  |user_2|user_2@databricks.com|AZ        |\n",
      "|41557         |41557   |2       |83114.0 |NY   |SKU-2|2  |user_2|user_2@databricks.com|AZ        |\n",
      "|62786         |62786   |2       |125572.0|CO   |SKU-4|2  |user_2|user_2@databricks.com|AZ        |\n",
      "|65482         |65482   |2       |130964.0|TX   |SKU-3|2  |user_2|user_2@databricks.com|AZ        |\n",
      "|77367         |77367   |2       |154734.0|AZ   |SKU-4|2  |user_2|user_2@databricks.com|AZ        |\n",
      "|79424         |79424   |2       |158848.0|MI   |SKU-5|2  |user_2|user_2@databricks.com|AZ        |\n",
      "|97392         |97392   |2       |194784.0|CO   |SKU-1|2  |user_2|user_2@databricks.com|AZ        |\n",
      "|101445        |101445  |2       |202890.0|AZ   |SKU-0|2  |user_2|user_2@databricks.com|AZ        |\n",
      "|115413        |115413  |2       |230826.0|MI   |SKU-0|2  |user_2|user_2@databricks.com|AZ        |\n",
      "|147972        |147972  |2       |295944.0|CA   |SKU-1|2  |user_2|user_2@databricks.com|AZ        |\n",
      "|165597        |165597  |2       |331194.0|TX   |SKU-3|2  |user_2|user_2@databricks.com|AZ        |\n",
      "|168503        |168503  |2       |337006.0|CA   |SKU-4|2  |user_2|user_2@databricks.com|AZ        |\n",
      "|173125        |173125  |2       |346250.0|MI   |SKU-4|2  |user_2|user_2@databricks.com|AZ        |\n",
      "|179091        |179091  |2       |358182.0|TX   |SKU-2|2  |user_2|user_2@databricks.com|AZ        |\n",
      "|237742        |237742  |2       |475484.0|CO   |SKU-0|2  |user_2|user_2@databricks.com|AZ        |\n",
      "|239091        |239091  |2       |478182.0|AZ   |SKU-4|2  |user_2|user_2@databricks.com|AZ        |\n",
      "|244502        |244502  |2       |489004.0|TX   |SKU-4|2  |user_2|user_2@databricks.com|AZ        |\n",
      "|246403        |246403  |2       |492806.0|AZ   |SKU-5|2  |user_2|user_2@databricks.com|AZ        |\n",
      "|260271        |260271  |2       |520542.0|CO   |SKU-2|2  |user_2|user_2@databricks.com|AZ        |\n",
      "+--------------+--------+--------+--------+-----+-----+---+------+---------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "usersDF \\\n",
    "    .orderBy(asc(\"uid\")) \\\n",
    "    .write \\\n",
    "    .format(\"parquet\") \\\n",
    "    .bucketBy(8, \"uid\") \\\n",
    "    .mode('overwrite') \\\n",
    "    .saveAsTable(\"UsersTbl\")\n",
    "\n",
    "# Orders: bucket by 8 on \"users_id\"\n",
    "ordersDF \\\n",
    "    .orderBy(asc(\"users_id\")) \\\n",
    "    .write \\\n",
    "    .format(\"parquet\") \\\n",
    "    .bucketBy(8, \"users_id\") \\\n",
    "    .mode('overwrite') \\\n",
    "    .saveAsTable(\"OrdersTbl\")\n",
    "\n",
    "# 2. Cache the tables in memory\n",
    "spark.sql(\"CACHE TABLE UsersTbl\")\n",
    "spark.sql(\"CACHE TABLE OrdersTbl\")\n",
    "\n",
    "# 3. Read them back in as DataFrames\n",
    "usersBucketDF = spark.table(\"UsersTbl\")\n",
    "ordersBucketDF = spark.table(\"OrdersTbl\")\n",
    "\n",
    "# 4. Perform the bucket-aware join and show results\n",
    "joinUsersOrdersBucketDF = ordersBucketDF.join(\n",
    "    usersBucketDF,\n",
    "    ordersBucketDF.users_id == usersBucketDF.uid\n",
    ")\n",
    "\n",
    "joinUsersOrdersBucketDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- SortMergeJoin [users_id#449L], [uid#310L], Inner\n",
      "   :- Sort [users_id#449L ASC NULLS FIRST], false, 0\n",
      "   :  +- Filter isnotnull(users_id#449L)\n",
      "   :     +- Scan In-memory table OrdersTbl [transaction_id#447L, quantity#448L, users_id#449L, amount#450, state#451, items#452], [isnotnull(users_id#449L)]\n",
      "   :           +- InMemoryRelation [transaction_id#447L, quantity#448L, users_id#449L, amount#450, state#451, items#452], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "   :                 +- *(1) ColumnarToRow\n",
      "   :                    +- FileScan parquet spark_catalog.default.orderstbl[transaction_id#447L,quantity#448L,users_id#449L,amount#450,state#451,items#452] Batched: true, Bucketed: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/khodosevichleo/Desktop/Weiterbildung/Spark/Learning-Spark-..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<transaction_id:bigint,quantity:bigint,users_id:bigint,amount:double,state:string,items:str..., SelectedBucketsCount: 8 out of 8\n",
      "   +- Sort [uid#310L ASC NULLS FIRST], false, 0\n",
      "      +- Filter isnotnull(uid#310L)\n",
      "         +- Scan In-memory table UsersTbl [uid#310L, login#311, email#312, user_state#313], [isnotnull(uid#310L)]\n",
      "               +- InMemoryRelation [uid#310L, login#311, email#312, user_state#313], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                     +- *(1) ColumnarToRow\n",
      "                        +- FileScan parquet spark_catalog.default.userstbl[uid#310L,login#311,email#312,user_state#313] Batched: true, Bucketed: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/khodosevichleo/Desktop/Weiterbildung/Spark/Learning-Spark-..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<uid:bigint,login:string,email:string,user_state:string>, SelectedBucketsCount: 8 out of 8\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinUsersOrdersBucketDF.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE UsersTbl\")\n",
    "spark.sql(\"DROP TABLE OrdersTbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
